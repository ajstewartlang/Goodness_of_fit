---
title: "Goodness of fit study"
author: ""
date: "01/05/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(psych)
library(lme4)
library(lmerTest)
library(emmeans)
library(performance)
```

First is Igor's code:

```{r, warning=FALSE, message=FALSE}
data <- read_csv("Explanation_QUALITY.csv")
data <- data[3:nrow(data),]
# nrow(data) # 157

dat0 <- filter(data, Finished == 1)
# nrow(dat0) # 142
dat <- filter(dat0, check == "7" & serious == "1" & UserLanguage == "EN")
# nrow(dat) # 134

# time (in secs) spent on survey
describe(as.numeric(as.data.frame(dat)[,6]))

# gender
table(dat$Gender)

# age
describe(as.numeric(dat$Age))

# mean responses
res <- sapply(23:58, function(x) mean(as.numeric(as.data.frame(dat)[,x]), na.rm = T))

# in the survey, we interchanged strong and weak explanations in the two groups
strong <- res[c(seq(1, 17, 2), seq(20, 36, 2))]
weak <- res[c(seq(2, 18, 2), seq(19, 35, 2))]

results <- c(strong, weak)
```

# Andrew's code to tidy the df so we can combine it with the eye-tracking data.

```{r, message=FALSE}
summary <- dat %>% 
  pivot_longer(cols = colnames(dat)[23:58], names_to = "Item", values_to = "Score") %>%
  select(Item, Score) %>%
  mutate(Item = factor(Item),
         Score = as.integer(Score)) %>%
  filter(!is.na(Score)) %>%
  group_by(Item) %>%
  summarise(mean_score = mean(Score)) 

summary$Item <- str_replace(summary$Item, "A_", "_A-")
summary$Item <- str_replace(summary$Item, "B_", "_B-")
  
summary <- summary %>%
  separate(col = Item, into = c("Item", "Condition"), sep = "_") 

summary$Condition <- str_replace(summary$Condition, "A-acceptance", "High")
summary$Condition <- str_replace(summary$Condition, "B-acceptance", "Low")

ready_to_combine <- summary %>%
  unite(col = "Item_Condition", c(Item, Condition), sep="_")
```

Read in the eye tracking data and combine it with our MTurk ratings data.

# First Pass
```{r, message=FALSE}
# Read in and combine with eye-tracking data

# First pass
first_pass <- read_csv("eye_data/FPs_plus_ratings.csv") %>%
  unite(col = "Item_Condition", c(Item, Fit), sep="_")

# Join the rating and eye-tracking data
joined_data_fp <- left_join(first_pass, ready_to_combine, by = "Item_Condition") %>%
  separate(col = "Item_Condition", into = (c("Item", "Condition")), sep = "_") %>%
  mutate(Condition = factor(Condition))
```

## Antecedent
```{r, warning=FALSE, message=FALSE}
model_antecedent <- lmer(Antecedent ~ mean_score + (1 | P.s) + (1 | Item), data = joined_data_fp)
summary(model_antecedent)
#check_model(model_antecedent)
```

No effect.

## Consequent
```{r, warning=FALSE, message=FALSE}
model_consequent <- lmer(Consequent ~ mean_score + (1 | P.s) + (1 | Item), data = joined_data_fp)
summary(model_consequent )
#check_model(model_consequent )
```

No effect

## Spillover
```{r}
model_spillover <- lmer(spillover ~ mean_score + (1 | P.s) + (1 | Item), data = joined_data_fp)
summary(model_spillover)
#check_model(model_spillover)
```

No effect.

# Regression Path
```{r, message=FALSE, warning=FALSE}
regression_path <- read_csv("eye_data/RPs_plus_ratings.csv") %>%
  unite(col = "Item_Condition", c(Item, Fit), sep="_")

# Join the rating and eye-tracking data
joined_data_rp <- left_join(regression_path , ready_to_combine, by = "Item_Condition") %>%
  separate(col = "Item_Condition", into = (c("Item", "Condition")), sep = "_") %>%
  mutate(Condition = factor(Condition))
```

## Antecedent
```{r}
model_antecedent <- lmer(Antecedent ~ mean_score + (1 | P.s) + (1 | Item), data = joined_data_rp)
summary(model_antecedent)
#check_model(model_antecedent)
```

No effect

## Consequent
```{r}
model_consequent<- lmer(Consequent ~ mean_score + (1 | P.s) + (1 | Item), data = joined_data_rp)
summary(model_consequent)
#check_model(model_consequent)
```

Nice effect - as goodness of rating goes up, reading time goes down

## Spillover
```{r}
model_spillover <- lmer(spillover ~ mean_score + (1 | P.s) + (1 | Item), data = joined_data_rp)
summary(model_spillover)
#check_model(model_spillover)
```

Same effect - as goodness of rating goes up, reading time goes down

# Total Time
```{r, message=FALSE, warning=FALSE}
total_time <- read_csv("eye_data/TTs_plus_ratings.csv") %>%
  unite(col = "Item_Condition", c(Item, Fit), sep="_")

# Join the rating and eye-tracking data
joined_data_tt <- left_join(total_time , ready_to_combine, by = "Item_Condition") %>%
  separate(col = "Item_Condition", into = (c("Item", "Condition")), sep = "_") %>%
  mutate(Condition = factor(Condition))
```

## Antecedent
```{r}
model_antecedent <- lmer(Antecedent ~ mean_score + (1 | P.s) + (1 | Item), data = joined_data_tt)
summary(model_antecedent)
#check_model(model_antecedent)
```

Same effect - as goodness of rating goes up, reading time goes down

## Consequent - note simpler random effects structure
```{r}
model_consequent<- lmer(Consequent ~ mean_score + (1 | P.s) , data = joined_data_tt)
summary(model_consequent)
#check_model(model_consequent)
```

No effect

## Spillover
```{r}
model_spillover <- lmer(spillover ~ mean_score + (1 | P.s) + (1 | Item), data = joined_data_tt)
summary(model_spillover)
#check_model(model_spillover)
```

No effect.

# Summary

So we have a nice (consistent) story across a number of eye-tracking measures. For regression path times (time to exit a region to the right - so includes re-reading before going past the target region) we see that as goodness of fit ratings go up, reading time goes down.  On regression path, the same effect holds for the spillover region.

On the total time measure (which is a measure of total time spent reading a region, incl re-reading) we find the same pattern as on regression path.  This time the effect emerges on the antecedent region (but nowhere else).  The effect on the antecedent times likely reflects re-reading of this region.  Again, as goodness of fit ratings go up, reading time goes down.
